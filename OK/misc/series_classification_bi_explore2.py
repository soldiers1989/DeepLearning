# coding: utf-8
from __future__ import print_function

import tensorflow as tf
import numpy as np
tf.reset_default_graph()
# 创建输入数据
X = np.random.randn(2, 4, 5)# 批次 、序列长度、样本维度

# 第二个样本长度为3
X[1,2:] = 0
seq_lengths = [4, 2]

Gstacked_rnn = []
Gstacked_bw_rnn = []
for i in range(3):
  Gstacked_rnn.append(tf.contrib.rnn.GRUCell(3))
  Gstacked_bw_rnn.append(tf.contrib.rnn.GRUCell(3))

#建立前向和后向的三层RNN
Gmcell = tf.contrib.rnn.MultiRNNCell(Gstacked_rnn)
Gmcell_bw = tf.contrib.rnn.MultiRNNCell(Gstacked_bw_rnn)

sGbioutputs, sGoutput_state_fw, sGoutput_state_bw = tf.contrib.rnn.stack_bidirectional_dynamic_rnn([Gmcell],[Gmcell_bw], X,sequence_length=seq_lengths, dtype=tf.float64)

Gbioutputs, Goutput_state_fw = tf.nn.bidirectional_dynamic_rnn(Gmcell,Gmcell_bw, X,sequence_length=seq_lengths,dtype=tf.float64)

#建立一个会话
sess = tf.InteractiveSession()
sess.run(tf.global_variables_initializer())

sgbresult,sgstate_fw,sgstate_bw=sess.run([sGbioutputs,sGoutput_state_fw,sGoutput_state_bw])
print("全序列：\n", sgbresult[0])
print("短序列：\n", sgbresult[1])
print('Gru的状态：',len(sgstate_fw[0]),'\n',sgstate_fw[0][0],'\n',sgstate_fw[0][1],'\n',sgstate_fw[0][2])
print('Gru的状态：',len(sgstate_bw[0]),'\n',sgstate_bw[0][0],'\n',sgstate_bw[0][1],'\n',sgstate_bw[0][2])

#全序列：
# [[ 1.19311338e-02  8.04132681e-03  3.31308389e-04  1.24738435e-02 -8.50487276e-02  9.40745771e-02]
#  [ 3.11281426e-02  2.24053887e-02  3.92652230e-03  1.37219700e-03 -5.93178546e-02  6.43401270e-02]
#  [ 3.21092447e-02  2.54082428e-02  5.58666966e-03  3.05420802e-03 -2.59310050e-02  2.81113416e-02]
#  [ 3.24786081e-02  2.65983480e-02  1.51541191e-02  2.93654512e-03 -7.57244273e-05 -2.87577970e-03]]
#短序列：
# [[ 0.00277366  0.0020676   0.00807069 -0.01222769  0.01769192 -0.01353805]
#  [ 0.00690449  0.00552507  0.01999395 -0.00346376  0.00803157 -0.00668309]
#  [ 0.          0.          0.          0.          0.          0.        ]
#  [ 0.          0.          0.          0.          0.          0.        ]]
#Gru的状态： 3 
# [[ 0.71222677 -0.15576328 -0.15435127][ 0.10909045 -0.13574404 -0.12655285]] 
# [[-0.0418109   0.12135266 -0.09755501][ 0.02555594  0.02631663 -0.05242381]] 
# [[0.03247861 0.02659835 0.01515412]   [0.00690449 0.00552507 0.01999395]]
#Gru的状态： 3 
# [[ 0.10939615 -0.09007517  0.4756096 ][-0.00807045  0.22927388 -0.12533228]] 
# [[ 0.06049569  0.05474533  0.17447143][ 0.00224654  0.01356028 -0.08815984]] 
# [[ 0.01247384 -0.08504873  0.09407458][-0.01222769  0.01769192 -0.01353805]]

gbresult, state_fw=sess.run([Gbioutputs, Goutput_state_fw])

print("正向：\n", gbresult[0])
print("反向：\n", gbresult[1])
print('状态：',len(state_fw),'\n',state_fw[0],'\n',state_fw[1])  #state_fw[0]：【层，批次，cell个数】 重头到最后一个序列
print(state_fw[0][-1],state_fw[1][-1])
out  = np.concatenate((state_fw[0][-1],state_fw[1][-1]),axis = 1)
print("拼接",out)

#正向：
# [[[0.01193113 0.00804133 0.00033131]
#   [0.03112814 0.02240539 0.00392652]
#   [0.03210924 0.02540824 0.00558667]
#   [0.03247861 0.02659835 0.01515412]]
#
#  [[0.00277366 0.0020676  0.00807069]
#   [0.00690449 0.00552507 0.01999395]
#   [0.         0.         0.        ]
#   [0.         0.         0.        ]]]
#反向：
# [[[ 1.24738435e-02 -8.50487276e-02  9.40745771e-02]
#   [ 1.37219700e-03 -5.93178546e-02  6.43401270e-02]
#   [ 3.05420802e-03 -2.59310050e-02  2.81113416e-02]
#   [ 2.93654512e-03 -7.57244273e-05 -2.87577970e-03]]
#
#  [[-1.22276889e-02  1.76919177e-02 -1.35380485e-02]
#   [-3.46376330e-03  8.03156995e-03 -6.68308801e-03]
#   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]
#   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]]
#状态： 2 
# (array([[ 0.71222677, -0.15576328, -0.15435127], [ 0.10909045, -0.13574404, -0.12655285]]), 
#  array([[-0.0418109 ,  0.12135266, -0.09755501], [ 0.02555594,  0.02631663, -0.05242381]]), 
#  array([[0.03247861, 0.02659835, 0.01515412],    [ 0.00690449, 0.00552507, 0.01999395]])) 
# (array([[ 0.10939615, -0.09007517,  0.4756096 ], [-0.00807045,  0.22927388, -0.12533228]]), 
#  array([[ 0.06049569,  0.05474533,  0.17447143], [ 0.00224654,  0.01356028, -0.08815984]]), 
#  array([[ 0.01247384, -0.08504873,  0.09407458], [-0.01222769,  0.01769192, -0.01353805]]))
#[[0.03247861 0.02659835 0.01515412][0.00690449 0.00552507 0.01999395]] 
#[[ 0.01247384 -0.08504873  0.09407458][-0.01222769  0.01769192 -0.01353805]]
#拼接 [[ 0.03247861  0.02659835  0.01515412  0.01247384 -0.08504873  0.09407458]
#      [ 0.00690449  0.00552507  0.01999395 -0.01222769  0.01769192 -0.01353805]]

#通过将正反向的状态拼接起来才可以获得双向RNN的最终输出特征。千万不要直接拿着输出不加处理的来进行后续的运算，这会损失一大部分的运算特征。